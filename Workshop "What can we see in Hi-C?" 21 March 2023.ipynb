{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dced82",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the workshop \"What can we see in Hi-C?\" by Leonid Mirny. \n",
    "Your assistant for this workshop is Aleksandra (Alex) Galitsyna. \n",
    "For any questions, feel free to reach out to agalitizina@gmail.com\n",
    "\n",
    "This workshop is mostly based on tutorials of Open Chromosome Collective (Open2C). \n",
    "For more detailed examples of Hi-C data analysis, see: https://github.com/open2c/open2c_examples\n",
    "\n",
    "\n",
    "## Workshop outline\n",
    "\n",
    "\n",
    "\n",
    "1. [Qualitative analysis](#Qualitative-analysis-of-Hi-C-maps)\n",
    "\n",
    "    - [Databases for Hi-C data](#Databases-for-Hi-C-data)\n",
    "    \n",
    "    - [Interactive browsers for Hi-C](#Interactive-browsers-for-Hi-C)\n",
    "    \n",
    "    - [Navigate Hi-C maps: TADs, dots, compartents](#Navigate-Hi-C-maps)\n",
    "    \n",
    "    - [Associate Hi-C with other epigenetics data](#Associate-Hi-C-with-other-epigenetics-data)\n",
    "\n",
    "2. [Quantitative analysis](#Quantitative-analysis-of-Hi-C-maps)\n",
    "\n",
    "    - [Load and navigate Hi-C in Python](#Load-and-navigate-Hi-C-in-Python)\n",
    "    \n",
    "    - [Scaling plots](#Scaling-plots)\n",
    "    \n",
    "    - [Insulation](#Insulation)\n",
    "    \n",
    "    - [Pileups](#Pileups)\n",
    "    \n",
    "    - [Compartments](#Compartments)\n",
    "    \n",
    "    - [Saddle plots](#Saddle-plots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a11a42",
   "metadata": {},
   "source": [
    "## Qualitative analysis of Hi-C maps\n",
    "\n",
    "[go top](#Workshop-outline)\n",
    "\n",
    "### Databases for Hi-C data\n",
    "\n",
    "Hi-C data can be found at various public databases, including broad-range sequencing storages (GEO, SRA, ENA, ArrayExpress, DDBJ), [ENCODE](https://www.encodeproject.org/matrix/?type=Experiment&control_type!=*&status=released&perturbed=false&assay_title=intact+Hi-C&assay_title=in+situ+Hi-C&assay_title=dilution+Hi-C) and [4DN Data Portal](https://data.4dnucleome.org/). \n",
    "\n",
    "[4DN](https://data.4dnucleome.org/) deposits raw sequencing data, processed data in widely accepted formats (.hic and .mcool) and annotation tracks (such as insulation and compartments).\n",
    "\n",
    "▸ **Practice task. Get familiar with 4DN database.**\n",
    "\n",
    "\n",
    "Select dataset and download it to the local computer (this file is ~12.Gb, might take ~ 7 minutes to download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O -L --user GY46LECU:uc2g6uxqv3ojobes https://data.4dnucleome.org/files-processed/4DNFI9GMP2J8/@@download/4DNFI9GMP2J8.mcool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f47ee3-9d43-4db0-b155-ed3fe3c5bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv 4DNFI9GMP2J8.mcool Micro-C_hESC1_4DNFI9GMP2J8.mcool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63653a98-0840-40e7-80f5-7ed347f7100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!resgen sync datasets WinterSchoolCurie2023 test Micro-C_hESC1_4DNFI9GMP2J8.mcool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21312b2a-842e-40ab-b1c2-aa3acb7d29ca",
   "metadata": {},
   "source": [
    "### Interactive browsers for Hi-C\n",
    "[go top](#Workshop-outline)\n",
    "\n",
    "<draft!>\n",
    "\n",
    "- Now go to resgen and register there with your e-mail.\n",
    "\n",
    "- Let the TA know your username, you will be added to the group: https://resgen.io/WinterSchoolCurie2023/\n",
    "\n",
    "- For your convenience, we've already loaded test dataset to the project https://resgen.io/WinterSchoolCurie2023/test/\n",
    "\n",
    "Check it our and create a view with chromosome annotations and genes there!\n",
    "\n",
    "You may save the view, but make sure to add your name/username (in a recognisable form) at the beginning of the view name, so you can always regognise it. \n",
    "\n",
    "#### Adding new data to resgen\n",
    "\n",
    "Now, let's add epigenetic tracks. \n",
    "\n",
    "Go to ENCODE and select CTCF bigwig file for h1-ESC cells there.\n",
    "\n",
    "You may load this track to resgen via the browser. \n",
    "\n",
    "▸ **Practice task. Load your data to resgen and create a view.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318e95e-4b7c-487b-9649-0ca89993f283",
   "metadata": {},
   "source": [
    "### Navigate Hi-C maps\n",
    "[go top](#Workshop-outline)\n",
    "\n",
    "Look for TADs, compartments, loops/dots in your dataset. \n",
    "\n",
    "### Associate Hi-C with other epigenetics data\n",
    "[go top](#Workshop-outline)\n",
    "\n",
    "Add more functional annotations to resgen. It may be your favorite histone modification or transcription factor binding. \n",
    "\n",
    "▸ Open-end task: add any modification that you like from ENCODE and try to visually analyse the relation to Hi-C, how are they related to TADs and compartments; select the region that you like the most (effect is most pronounced; you will study it later in more details)\n",
    "\n",
    "<!---  Take Hi-C maps from 4DN browser (potentially, Micro-C as there is a lot to be seen)\n",
    "Load data to Resgen through Python\n",
    "Add positions of genes and tracks of chromosomes\n",
    "Navigation on Hi-C maps: TADs, compartments, loops/dots\n",
    "Change between linear and logarithmic scale\n",
    "Adding functional annotations: \n",
    "CTCF\n",
    "Histone modification: H3K27ac\n",
    "Open-end task: add any modification that you like from ENCODE and try to visually analyse the relation to Hi-C, how are they related to TADs and compartments; select the region that you like the most (effect is most pronounced; you will study it later in more details) ---->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f752e",
   "metadata": {},
   "source": [
    "## Quantitative analysis of Hi-C maps\n",
    "\n",
    "[go top](#Workshop-outline)\n",
    "\n",
    "We think of Hi-C map as a 2D matrix with numbers. Each row and column corresponds to the bin in the genome, and the number represents the probability of interactions between corresponding two bins.\n",
    "\n",
    "<!--- Quantitative Hi-C data analysis in Python: start with data visualisation in Python. \n",
    "Scalings; scaling derivative; demonstration of the changes in Rad21KO <30 min>\n",
    "Insulation, visualization of the track  for WT <15 min>\n",
    "Stackup of insulation at boundaries (CTCF or boundary-prominence defined)  for WT\n",
    "On-diagonal pileup: average boundary  for WT\n",
    "Off-diagonal pileup: how boundaries interact with each other for WT\n",
    "Compartments, visualization of the track; demonstration of changes in mutants <15 min>\n",
    "Saddle plot for WT\n",
    "Open-end task: do we see the changes of compartmental strength in mutants? Repeat all the analysis by yourself. They actually can do scatter plots. <Compare and do that with any methods you’ve learned or that you have>\n",
    "---->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f72da",
   "metadata": {},
   "source": [
    "### Load and navigate Hi-C in Python\n",
    "[go top](#Workshop-outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import libraries for Hi-C analysis\n",
    "\n",
    "import cooler\n",
    "import cooltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooltools.print_available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5abee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data\n",
    "# this file is 145 Mb, and may take a few seconds to download\n",
    "\n",
    "data_dir = './data/'\n",
    "cool_file = cooltools.download_data(\"HFF_MicroC\", cache=True, data_dir=data_dir)    \n",
    "print(cool_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddd04f",
   "metadata": {},
   "source": [
    "The file we just downloaded, test.mcool, contains Micro-C data from HFF cells for two chromosomes in a [multi-resolution mcool format](https://cooler.readthedocs.io/en/latest/schema.html?highlight=mcool#multi-resolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print which resolutions are stored in the mcool, use list_coolers\n",
    "cooler.fileops.list_coolers(f'{data_dir}/test.mcool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to load a cooler with a specific resolution use the following syntax:\n",
    "clr = cooler.Cooler(f'{data_dir}/test.mcool::resolutions/1000000')\n",
    "\n",
    "### to print chromosomes and binsize for this cooler\n",
    "print(f'chromosomes: {clr.chromnames}, binsize: {clr.binsize}')\n",
    "\n",
    "### to make a list of chromosome start/ends in bins:\n",
    "chromstarts = []\n",
    "for i in clr.chromnames:\n",
    "    print(f'{i} : {clr.extent(i)}')\n",
    "    chromstarts.append(clr.extent(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(\n",
    "    figsize=(7,6))\n",
    "im = ax.matshow((clr.matrix(balance=False)[:]),vmax=500); \n",
    "plt.colorbar(im ,fraction=0.046, pad=0.04, label='raw counts')\n",
    "ax.set(xticks=chromstarts, xticklabels=clr.chromnames,\n",
    "       xlabel='position, chrom#', ylabel='position, bin#')\n",
    "ax.xaxis.set_label_position('top')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757354f0-5b3b-453c-b85d-7890992a489d",
   "metadata": {},
   "source": [
    "#### Plotting subregions\n",
    "\n",
    "Below, we fetch and plot an individual chromosome (left) and a region of a chromosome (right) using `clr.fetch()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead5be8-21d3-4987-ad08-bbb6c606cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot ticks in terms of megabases we use the EngFormatter \n",
    "# https://matplotlib.org/gallery/api/engineering_formatter.html\n",
    "from matplotlib.ticker import EngFormatter\n",
    "bp_formatter = EngFormatter('b')\n",
    "\n",
    "def format_ticks(ax, x=True, y=True, rotate=True):\n",
    "    if y:\n",
    "        ax.yaxis.set_major_formatter(bp_formatter)\n",
    "    if x:\n",
    "        ax.xaxis.set_major_formatter(bp_formatter)\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if rotate:\n",
    "        ax.tick_params(axis='x',rotation=45)\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    figsize=(14,4),\n",
    "    ncols=3)\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.matshow(clr.matrix(balance=False)[:], vmax=2500); \n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "ax.set_xticks(chromstarts)\n",
    "ax.set_xticklabels(clr.chromnames)\n",
    "ax.set_yticks(chromstarts)\n",
    "ax.set_yticklabels(clr.chromnames)\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.set_title('All data')\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False).fetch('chr17'),\n",
    "    vmax=2500, \n",
    "    extent=(0,clr.chromsizes['chr17'], clr.chromsizes['chr17'], 0)\n",
    ");\n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "ax.set_title('chr17', y=1.08)\n",
    "ax.set_ylabel('position, Mb')\n",
    "format_ticks(ax)\n",
    "\n",
    "ax = axs[2]\n",
    "start, end = 30_000_000, 60_000_000\n",
    "region = ('chr17', start, end)\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False).fetch(region),\n",
    "    vmax=2500, \n",
    "    extent=(start, end, end, start)\n",
    "); \n",
    "ax.set_title(f'chr17:{start:,}-{end:,}', y=1.08)\n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "format_ticks(ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8407ef-8e29-4c30-b371-f9ca2dc541b6",
   "metadata": {},
   "source": [
    "#### Logarithmic color scale\n",
    "\n",
    "Since C data has a high dynamic range, we often plot the data in log-scale. This enables simultaneous visualization of features near and far from the diagonal in a consistent colorscale. Note that regions with no reported counts are evident as white stripes at both centromeres. This occurs because reads are not uniquely mapped to these highly-repetitive regions. These regions are masked before [matrix balancing](#balancing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8e993-3d27-4761-a787-490d97a92f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmaps at megabase resolution with 3 levels of zoom in log-scale with a consistent colormap#\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    figsize=(14,4),\n",
    "    ncols=3)\n",
    "bp_formatter = EngFormatter('b')\n",
    "norm = LogNorm(vmax=50_000)\n",
    "\n",
    "ax = axs[0]\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False)[:], \n",
    "    norm=norm,\n",
    ") \n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "ax.set_xticks(chromstarts)\n",
    "ax.set_xticklabels(clr.chromnames)\n",
    "ax.set_yticks(chromstarts)\n",
    "ax.set_yticklabels(clr.chromnames)\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.set_title('All data')\n",
    "\n",
    "ax = axs[1]\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False).fetch('chr17'),\n",
    "    norm=norm,\n",
    "    extent=(0,clr.chromsizes['chr17'], clr.chromsizes['chr17'], 0)\n",
    ");\n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "ax.set_title('chr17', y=1.08)\n",
    "ax.set(ylabel='position, Mb', xlabel='position, Mb')\n",
    "format_ticks(ax)\n",
    "\n",
    "ax = axs[2]\n",
    "start, end = 30_000_000, 60_000_000\n",
    "region = ('chr17', start, end)\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False).fetch(region),\n",
    "    norm=norm,\n",
    "    extent=(start, end, end, start)\n",
    "); \n",
    "ax.set_title(f'chr17:{start:,}-{end:,}', y=1.08)\n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='raw counts');\n",
    "ax.set(xlabel='position, Mb')\n",
    "format_ticks(ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88af6b-dddf-4150-9318-98a69eff4bdd",
   "metadata": {},
   "source": [
    "#### Colormaps\n",
    "`cooltools.lib.plotting` registers a set of colormaps that are useful for visualizing C data.\n",
    "In particular, the `fall` colormap (inspired by [colorbrewer](https://colorbrewer2.org/#type=sequential&scheme=YlOrRd&n=9)) offers a high dynamic range, linear, option for visualizing Hi-C matrices. This often displays features more clearly than red colormaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0474792-442d-4c4f-9f29-fc031384fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the corrected data in fall heatmap and compare to the white-red colormap ###\n",
    "### thanks for the alternative collormap naming to https://twitter.com/HiC_memes/status/1286326919122825221/photo/1###\n",
    "import cooltools.lib.plotting\n",
    "\n",
    "vmax = 5000\n",
    "norm = LogNorm(vmin=1, vmax=100_000)\n",
    "fruitpunch = sns.blend_palette(['white', 'red'], as_cmap=True)\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    figsize=(13, 10),\n",
    "    nrows=2, \n",
    "    ncols=2,\n",
    "    sharex=True, sharey=True)\n",
    "\n",
    "ax = axs[0, 0]\n",
    "ax.set_title('Pumpkin Spice')\n",
    "im = ax.matshow(clr.matrix(balance=False)[:], vmax=vmax, cmap='fall'); \n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='counts (linear)');\n",
    "plt.xticks(chromstarts,clr.chromnames);\n",
    "\n",
    "ax = axs[0, 1]\n",
    "ax.set_title('Fruit Punch')\n",
    "im3 = ax.matshow(clr.matrix(balance=False)[:], vmax=vmax, cmap=fruitpunch); \n",
    "plt.colorbar(im3, ax=ax, fraction=0.046, pad=0.04, label='counts (linear)');\n",
    "plt.xticks(chromstarts,clr.chromnames);\n",
    "\n",
    "ax = axs[1, 0]\n",
    "im = ax.matshow(clr.matrix(balance=False)[:], norm=norm, cmap='fall'); \n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='counts (log)');\n",
    "plt.xticks(chromstarts,clr.chromnames);\n",
    "\n",
    "ax = axs[1, 1]\n",
    "im3 = ax.matshow(clr.matrix(balance=False)[:], norm=norm, cmap=fruitpunch); \n",
    "plt.colorbar(im3, ax=ax, fraction=0.046, pad=0.04, label='counts (log)');\n",
    "plt.xticks(chromstarts,clr.chromnames);\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a68106-df9d-4767-ba3d-71ae0bb2dd1f",
   "metadata": {},
   "source": [
    "The utility of fall colormaps becomes more noticeable at higher resolutions and higher degrees of zoom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bc963-1128-41bf-90c7-883c175b978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the corrected data in fall heatmap ###\n",
    "import cooltools.lib.plotting\n",
    "clr_10kb = cooler.Cooler(f'{data_dir}/test.mcool::resolutions/10000')\n",
    "\n",
    "region = 'chr17:30,000,000-35,000,000'\n",
    "extents = (start, end, end, start)\n",
    "norm = LogNorm(vmin=1, vmax=1000)\n",
    "\n",
    "f, axs = plt.subplots(\n",
    "    figsize=(13, 10),\n",
    "    nrows=2, \n",
    "    ncols=2,\n",
    "    sharex=True, \n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "ax = axs[0, 0]\n",
    "im = ax.matshow(\n",
    "    clr_10kb.matrix(balance=False).fetch(region),\n",
    "    cmap='fall',\n",
    "    vmax=200,\n",
    "    extent=extents\n",
    "); \n",
    "plt.colorbar(im, ax=ax ,fraction=0.046, pad=0.04, label='counts');\n",
    "\n",
    "ax = axs[0, 1]\n",
    "im2 = ax.matshow(\n",
    "    clr_10kb.matrix(balance=False).fetch(region),\n",
    "    cmap=fruitpunch, \n",
    "    vmax=200,\n",
    "    extent=extents\n",
    "); \n",
    "plt.colorbar(im2, ax=ax, fraction=0.046, pad=0.04, label='counts');\n",
    "\n",
    "ax = axs[1, 0]\n",
    "im = ax.matshow(\n",
    "    clr_10kb.matrix(balance=False).fetch(region),\n",
    "    cmap='fall',\n",
    "    norm=norm,\n",
    "    extent=extents\n",
    "); \n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04, label='counts');\n",
    "\n",
    "ax = axs[1, 1]\n",
    "im2 = ax.matshow(\n",
    "    clr_10kb.matrix(balance=False).fetch(region),\n",
    "    cmap=fruitpunch, \n",
    "    norm=norm,\n",
    "    extent=extents\n",
    "); \n",
    "plt.colorbar(im2, ax=ax, fraction=0.046, pad=0.04, label='counts');\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    format_ticks(ax, rotate=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0780e57-12f8-4b5d-a5a8-546d718f1f74",
   "metadata": {},
   "source": [
    "#### Balancing <a id='Balancing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de83c7-69d7-4cdf-a8c4-bd335e956db0",
   "metadata": {},
   "source": [
    "When `(balance=True)` is passed to cooler.matrix(), this applies correction weights calculated from matrix balancing. Matrix balancing (also called iterative correction and KR normalization) removes multiplicative biases, which constitute the majority of known biases, from C data.\n",
    "By default, the rows & columns of the matrix are  normalized to sum to one (note that the colormap scale differs after balancing). Biases, also called weights for normalization, are stored in the `weight` column of the bin table given by `clr.bins()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5458614-ebb8-45f3-a097-dc5434bda098",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr.bins()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b64ac2-c42e-43b4-a551-0974785b0fe1",
   "metadata": {},
   "source": [
    "Before balancing, cooler also applies filters to remove low-coverage bins (note that peri-centromeric bins are completely removed in the normalized data). Filtered bins are stored as `np.nan` in the weights. \n",
    "\n",
    "Matrices appear visually smoother after removal of biases. Smoother matrices are expected for chromosomes, as adjacent regions along a chromosome are connected and should only slowly vary in their contact frequencies with other regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b8b19-c9e8-49dc-9d40-e22abd03b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the raw and corrected data in logscale ###\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt_width=4\n",
    "f, axs = plt.subplots(\n",
    "    figsize=( plt_width+plt_width+2, plt_width+plt_width+1),\n",
    "    ncols=4,\n",
    "    nrows=3,\n",
    "    gridspec_kw={'height_ratios':[4,4,1],\"wspace\":0.01,'width_ratios':[1,.05,1,.05]},\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "norm = LogNorm(vmax=0.1)\n",
    "norm_raw = LogNorm(vmin=1, vmax=10_000)\n",
    "\n",
    "ax = axs[0,0]\n",
    "im = ax.matshow(\n",
    "    clr.matrix(balance=False)[:], \n",
    "    norm=norm_raw,  \n",
    "    cmap='fall',\n",
    "    aspect='auto'\n",
    "); \n",
    "ax.xaxis.set_visible(False)\n",
    "ax.set_title('full matrix')\n",
    "ax.set_ylabel('raw', fontsize=16)\n",
    "\n",
    "cax = axs[0,1]\n",
    "plt.colorbar(im, cax=cax, label='raw counts')\n",
    "\n",
    "ax = axs[1,0]\n",
    "im = ax.matshow(\n",
    "    clr.matrix()[:], \n",
    "    norm=norm,  \n",
    "    cmap='fall',\n",
    "); \n",
    "ax.xaxis.set_visible(False)\n",
    "ax.set_ylabel('balanced', fontsize=16)\n",
    "\n",
    "cax = axs[1,1]\n",
    "plt.colorbar(im, cax=cax, label='corrected freqs')\n",
    "\n",
    "ax1 = axs[2,0]\n",
    "weights = clr.bins()[:]['weight'].values\n",
    "ax1.plot(weights)\n",
    "ax1.set_xlim([0, len(clr.bins()[:])])\n",
    "ax1.set_xlabel('position, bins')\n",
    "\n",
    "ax1 = axs[2,1]\n",
    "ax1.set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "start = 30_000_000\n",
    "end = 32_000_000\n",
    "region = ('chr17', start, end)\n",
    "\n",
    "ax = axs[0,2]\n",
    "im = ax.matshow(\n",
    "        clr_10kb.matrix(balance=False).fetch(region), \n",
    "    norm=norm_raw,  \n",
    "    cmap='fall'\n",
    "); \n",
    "ax.set_title(f'chr17:{start:,}-{end:,}')\n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "cax = axs[0,3]\n",
    "plt.colorbar(im, cax=cax, label='raw counts');\n",
    "\n",
    "ax = axs[1,2]\n",
    "im = ax.matshow(\n",
    "    clr_10kb.matrix().fetch(region), \n",
    "    norm=norm,  \n",
    "    cmap='fall',\n",
    "    extent=(start, end, end, start)\n",
    "); \n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "cax = axs[1,3]\n",
    "plt.colorbar(im, cax=cax, label='corrected frequencies');\n",
    "\n",
    "ax1 = axs[2,2]\n",
    "weights = clr_10kb.bins().fetch(region)['weight'].values\n",
    "ax1.plot(\n",
    "    np.linspace(start, end, len(weights)),\n",
    "    weights\n",
    ")\n",
    "format_ticks(ax1, y=False, rotate=False)\n",
    "ax1.set_xlim(start, end);\n",
    "ax1.set_xlabel('chr17 position, bp')\n",
    "\n",
    "ax1 = axs[2,3]\n",
    "ax1.set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e3e18",
   "metadata": {},
   "source": [
    "### Scaling plots\n",
    "[go top](#Workshop-outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac9e6c-8603-4ed7-98e0-b0e573bf527b",
   "metadata": {},
   "source": [
    "In Hi-C maps, contact frequency decreases very strongly with **genomic separation** (also referred to as **genomic distance**). In the Hi-C field, this decay is often interchangeably referred to as the: \n",
    "\n",
    "* **expected** because one \"expects\" a certain average contact frequency at a given genomic separation\n",
    "* **scaling** which is borrowed from the polymer physics literature\n",
    "* **P(s) curve** contact *probability*, *P*, as a function of genomic *separation*, *s*. \n",
    "\n",
    "The rate of decay of contacts with genomic separation reflects the polymeric nature of chromosomes and can tell us about the global folding patterns of the genome. \n",
    "\n",
    "This decay has been observed to vary through the cell cycle, across cell types, and after degredation of structural maintenance of chromosomes complexes (SMCs) in both interphase and mitosis. \n",
    "\n",
    "The goals of this notebook are to:\n",
    "\n",
    "* calculate the P(s) of a given cooler\n",
    "* plot the P(s) curve\n",
    "* smooth the P(s) curve with logarithmic binning\n",
    "* plot the derivative of P(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a7451-3445-4229-a43b-531bf03316f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# import semi-core packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-poster')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import open2c libraries\n",
    "import bioframe\n",
    "\n",
    "import cooler\n",
    "import cooltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a14d7e-0c22-4ca3-8e75-be2391262d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "# create a view with chromosome arms using chromosome sizes and definition of centromeres\n",
    "hg38_arms = bioframe.make_chromarms(hg38_chromsizes,  hg38_cens)\n",
    "\n",
    "# select only those chromosomes available in cooler\n",
    "hg38_arms = hg38_arms[hg38_arms.chrom.isin(clr.chromnames)].reset_index(drop=True)\n",
    "hg38_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69782420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Hi-C map at a 1kb resolution from a cooler file.\n",
    "resolution = 1000 # note this might be slightly slow on a laptop\n",
    "                  # and could be lowered to 10kb for increased speed\n",
    "clr = cooler.Cooler('./data/test.mcool::/resolutions/'+str(resolution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc1ae5-90d4-4568-969e-1a11ac7b0cd6",
   "metadata": {},
   "source": [
    "#### Calculate the P(s) curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7175ee-ed9e-40d2-ad02-fc7d91f78e4b",
   "metadata": {},
   "source": [
    "To calculate the average contact frequency as a function of genomic separation, we use the fact that each diagonal of a Hi-C map records contacts between loci separated by the same genomic distance. For example, the 3rd diagonal of our matrix contains contacts between loci separated by 3-4kb (note that diagonals are 0-indexed). Thus, we calculate the average contact frequency, *P(s)*, at a given genomic distance, *s*, as the average value of all pixels of the corresponding diagonal. This operation is performed by `cooltools.expected_cis`.\n",
    "\n",
    "Note that we calculate the *P(s)* separately for each chromosomal **arm**, by providing  `hg38_arms` as a `view_df`. This way we will ignore contacts accross the centromere, which is generally a good idea, since such contacts have a slightly different decay versus genomic separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b20fb0-9338-4e0a-b669-33af20143221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvd == contacts-vs-distance\n",
    "cvd = cooltools.expected_cis(\n",
    "    clr=clr,\n",
    "    view_df=hg38_arms,\n",
    "    smooth=False,\n",
    "    aggregate_smoothed=False,\n",
    "    nproc=4 #if you do not have multiple cores available, set to 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a395c81-9d5b-43e5-99ea-0e30bae33359",
   "metadata": {},
   "source": [
    "This function calculates average contact frequency for raw and normalized interactions ( `count.avg` and `balanced.avg`) for each diagonal and each regions in the `hg38_arms` of a Hi-C map. It aslo keeps the sum of raw and normalized interaction counts (`count.sum` and `balanced.sum`) as well as the number of valid (i.e. non-masked) pixels at each diagonal, `n_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559058a-22d7-4c04-b886-059dcfb95ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cvd.head(4))\n",
    "display(cvd.tail(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbfc7e-ad4f-412a-97b0-dd1f531a4383",
   "metadata": {},
   "source": [
    "Note that the data from the first couple of diagonals are masked. This is done intentionally, since interactions at these diagonals (very short-ranged) are contaminated by non-informative Hi-C byproducts - dangling ends and self-circles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8bc2ec-cd04-4682-a2e1-711cfffbd975",
   "metadata": {},
   "source": [
    "#### Plot the P(s) curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509df096-aefe-4f3d-b1aa-4e406d16edcc",
   "metadata": {},
   "source": [
    "Time to plot *P(s)* !\n",
    "\n",
    "The first challenge  is that Hi-C has a very wide dynamic range. Hi-C probes genomic separations ranging from 100s to 100,000,000s of basepairs and contact frequencies also tend to span many orders of magnitude.\n",
    "\n",
    "Plotting such data in the linear scale would reveal only a part of the whole picture. Instead, we typically switch to double logarithmic (aka log-log) plots, where the x and y coordinates vary by orders of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61545c-c7a5-4745-b47d-c9d976b4d6e2",
   "metadata": {},
   "source": [
    "With the flags used above, `expected_cis()` does not smooth or aggregate across regions. This can lead to noisy P(s) curves for each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321bf87-df0b-4fd5-b919-ae2bf1a98c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd['s_bp'] = cvd['dist']* resolution\n",
    "f, ax = plt.subplots(1,1)\n",
    "\n",
    "for region in hg38_arms['name']:\n",
    "    ax.loglog(\n",
    "        cvd['s_bp'].loc[cvd['region1']==region],\n",
    "        cvd['balanced.avg'].loc[cvd['region1']==region],\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel='separation, bp', \n",
    "        ylabel='IC contact frequency')\n",
    "    ax.set_aspect(1.0)\n",
    "    ax.grid(lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f5e8e-133f-49df-a3b0-8733d424a98d",
   "metadata": {},
   "source": [
    "The non-smoothed curves plotted above form characteristic \"fans\" at longer separations. This happens for two reasons: (a) we plot values of **each** diagonal separately and thus each decade of s contains 10x more points, and (b) due to the polymer nature of chromosomes, contact frequency at large genomic separations are lower and thus more affected by sequencing depth.\n",
    "\n",
    "This issue is more that just cosmetic, as this noise would prevent us from doing finer analyses of *P(s)* and propagate into data derived from *P(s)*. However, there is a simple solution: we can smooth *P(s)* over multiple diagonals. This works because *P(s)* changes very gradually with *s*, so that consecutive diagonals have similar values. Furthermore, we can make each subsequent smoothing window wider than the previous one, so that each order of magnitude of genomic separation contains the same number of windows. Such aggregation is a little tricky to perform, so `cooltools.expected` implements this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd345eaf-4782-4ea7-81c1-89327ed78a85",
   "metadata": {},
   "source": [
    "#### Smoothing & aggregating P(s) curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef00585-4176-4438-b4fd-9f7d827f7f1b",
   "metadata": {},
   "source": [
    "Instead of the flags above, we can pass flags to `expected_cis()` that return smoothed and aggregated columns for futher analysis (which are on by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91304db5-8bdd-48b7-8c36-b0896867a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_smooth_agg = cooltools.expected_cis(\n",
    "    clr=clr,\n",
    "    view_df=hg38_arms,\n",
    "    smooth=True,\n",
    "    aggregate_smoothed=True,\n",
    "    nproc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637798b1-5570-4b68-910d-81d8b37fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cvd_smooth_agg.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92d8da-9159-4b36-8a38-9aff2c65f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_smooth_agg['s_bp'] = cvd_smooth_agg['dist']* resolution\n",
    "cvd_smooth_agg['balanced.avg.smoothed'].loc[cvd_smooth_agg['dist'] < 2] = np.nan\n",
    "f, ax = plt.subplots(1,1)\n",
    "\n",
    "for region in hg38_arms['name']:\n",
    "    ax.loglog(\n",
    "        cvd_smooth_agg['s_bp'].loc[cvd_smooth_agg['region1']==region],\n",
    "        cvd_smooth_agg['balanced.avg.smoothed'].loc[cvd_smooth_agg['region1']==region],\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel='separation, bp', \n",
    "        ylabel='IC contact frequency')\n",
    "    ax.set_aspect(1.0)\n",
    "    ax.grid(lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20473d6e-b51d-4b95-8404-d6e97d357ba9",
   "metadata": {},
   "source": [
    "The `balanced.avg.smoothed.agg` is averaged across regions, and shows the same exact curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb7391-7357-4fc3-8f0f-8a8a973a4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_smooth_agg['s_bp'] = cvd_smooth_agg['dist']* resolution\n",
    "cvd_smooth_agg['balanced.avg.smoothed.agg'].loc[cvd_smooth_agg['dist'] < 2] = np.nan\n",
    "f, ax = plt.subplots(1,1)\n",
    "\n",
    "for region in hg38_arms['name']:\n",
    "    ax.loglog(\n",
    "        cvd_smooth_agg['s_bp'].loc[cvd_smooth_agg['region1']==region],\n",
    "        cvd_smooth_agg['balanced.avg.smoothed.agg'].loc[cvd_smooth_agg['region1']==region],\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel='separation, bp', \n",
    "        ylabel='IC contact frequency')\n",
    "    ax.set_aspect(1.0)\n",
    "    ax.grid(lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc5519-55f3-44f4-99a4-1b62649fa54e",
   "metadata": {},
   "source": [
    "#### Plot the smoothed P(s) curve and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4978b8-85ed-4444-b986-3ae27e3b5339",
   "metadata": {},
   "source": [
    "Logbin-smoothing of P(s) reduces the \"fanning\" at longer s and enables us to plot the derivative of the P(s) curve in the log-log space. This derivative is extremely informative, as it can be compared to predictions from various polymer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15525348-ea94-4ddc-9b11-60ce1952ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just take a single value for each genomic separation\n",
    "cvd_merged = cvd_smooth_agg.drop_duplicates(subset=['dist'])[['s_bp', 'balanced.avg.smoothed.agg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7aaa3-3879-4691-8183-253ddd62718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derivative in log-log space\n",
    "der = np.gradient(np.log(cvd_merged['balanced.avg.smoothed.agg']),\n",
    "                  np.log(cvd_merged['s_bp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b5772-a3b2-4434-b257-dcd07af7d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(\n",
    "    figsize=(6.5,13),\n",
    "    nrows=2, \n",
    "    gridspec_kw={'height_ratios':[6,2]}, \n",
    "    sharex=True)\n",
    "ax = axs[0]\n",
    "ax.loglog(\n",
    "    cvd_merged['s_bp'],\n",
    "    cvd_merged['balanced.avg.smoothed.agg'],\n",
    "    '-',\n",
    "    markersize=5,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    ylabel='IC contact frequency',\n",
    "    xlim=(1e3,1e8)\n",
    ")\n",
    "ax.set_aspect(1.0)\n",
    "ax.grid(lw=0.5)\n",
    "\n",
    "\n",
    "ax = axs[1]\n",
    "ax.semilogx(\n",
    "    cvd_merged['s_bp'],\n",
    "    der,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlabel='separation, bp', \n",
    "    ylabel='slope')\n",
    "\n",
    "ax.grid(lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222348b",
   "metadata": {},
   "source": [
    "### Insulation\n",
    "\n",
    "[go top](#Workshop-outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797f980-55fd-477a-830f-8197e74edea3",
   "metadata": {},
   "source": [
    "Insulation is a simple concept, yet a powerful way to look at C data. Insulation is one aspect of locus-specific contact frequency at small genomic distances, and reflects the segmentation of the genome into domains.\n",
    "\n",
    "Insulation can be computed with multiple methods. One of the most common methods involves using a diamond-window score to generate an ***insulation profile***. To compute this profile, slide a diamond-shaped window along the genome, with one of the corners on the main diagonal of the matrix, and sum up the contacts within the window for each position.\n",
    "\n",
    "Insulation profiles reveal that certain locations have lower scores, reflecting lowered contact frequencies between upstream and downstream loci. These positions are often referred to as ***boundaries***, and are also obtained with multiple methods. Here we illustrate one thresholding method for determining boundaries from an insulation profile.\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "* Calculate the insulation score genome-wide and display it alongside an interaction matrix\n",
    "* Call insulating boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4ceaa-84f9-4dd8-8e41-9b017cf9df90",
   "metadata": {},
   "source": [
    "#### Calculating genome-wide contact insulation\n",
    "Here we load the Hi-C data at 10 kbp resolution and calculate insulation score with 4 different window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f27cd1-c1d9-44b3-83eb-4e3c12bc5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cooltools.lib.plotting\n",
    "from cooltools import insulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21ade2-1b7a-49cf-bd7a-663c1c7fc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10000  \n",
    "clr = cooler.Cooler(f'{data_dir}test.mcool::resolutions/{resolution}')\n",
    "windows = [3*resolution, 5*resolution, 10*resolution, 25*resolution]\n",
    "insulation_table = insulation(clr, windows, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44a3e6-08f5-448e-b425-727eda0805f1",
   "metadata": {},
   "source": [
    "This function returns a dataframe where rows correspond to genomic bins of the cooler.\n",
    "\n",
    "The columns of this insulation dataframe report the insulation score, the number of valid (non-nan) pixels, whether the given bin is valid, the boundary prominence (strength) and whether locus is called as a boundary after thresholding, for each of the window sizes provided to the function.\n",
    "\n",
    "Below we print the information returned for any window size, as well as the specific information for the largest window used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bdb41-6233-43ee-81a1-db3c620ea0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_window_summary =insulation_table.columns[[ str(windows[-1]) in i for i in insulation_table.columns]]\n",
    "\n",
    "insulation_table[['chrom','start','end','region','is_bad_bin']+list(first_window_summary)].iloc[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cb37a-d5ed-42a3-a2ef-f21c40e3a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help with plotting\n",
    "def pcolormesh_45deg(ax, matrix_c, start=0, resolution=1, *args, **kwargs):\n",
    "    start_pos_vector = [start+resolution*i for i in range(len(matrix_c)+1)]\n",
    "    import itertools\n",
    "    n = matrix_c.shape[0]\n",
    "    t = np.array([[1, 0.5], [-1, 0.5]])\n",
    "    matrix_a = np.dot(np.array([(i[1], i[0])\n",
    "                                for i in itertools.product(start_pos_vector[::-1],\n",
    "                                                           start_pos_vector)]), t)\n",
    "    x = matrix_a[:, 1].reshape(n + 1, n + 1)\n",
    "    y = matrix_a[:, 0].reshape(n + 1, n + 1)\n",
    "    im = ax.pcolormesh(x, y, np.flipud(matrix_c), *args, **kwargs)\n",
    "    im.set_rasterized(True)\n",
    "    return im\n",
    "\n",
    "from matplotlib.ticker import EngFormatter\n",
    "bp_formatter = EngFormatter('b')\n",
    "def format_ticks(ax, x=True, y=True, rotate=True):\n",
    "    if y:\n",
    "        ax.yaxis.set_major_formatter(bp_formatter)\n",
    "    if x:\n",
    "        ax.xaxis.set_major_formatter(bp_formatter)\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if rotate:\n",
    "        ax.tick_params(axis='x',rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ce345-6eed-4191-b291-34ba544ae10f",
   "metadata": {},
   "source": [
    "Let's see what the insulation track at the highest resolution looks like, next to a rotated Hi-C matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d944a3-ff0f-465e-8dad-5b606187d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import bioframe\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "start = 10_500_000\n",
    "end = start+ 90*windows[0]\n",
    "region = ('chr2', start, end)\n",
    "norm = LogNorm(vmax=0.1, vmin=0.001)\n",
    "data = clr.matrix(balance=True).fetch(region)\n",
    "f, ax = plt.subplots(figsize=(18, 6))\n",
    "im = pcolormesh_45deg(ax, data, start=region[1], resolution=resolution, norm=norm, cmap='fall')\n",
    "ax.set_aspect(0.5)\n",
    "ax.set_ylim(0, 10*windows[0])\n",
    "format_ticks(ax, rotate=False)\n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.1, aspect=6)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "insul_region = bioframe.select(insulation_table, region)\n",
    "\n",
    "ins_ax = divider.append_axes(\"bottom\", size=\"50%\", pad=0., sharex=ax)\n",
    "ins_ax.set_prop_cycle(plt.cycler(\"color\", plt.cm.plasma(np.linspace(0,1,5))))\n",
    "ins_ax.plot(insul_region[['start', 'end']].mean(axis=1), \n",
    "            insul_region['log2_insulation_score_'+str(windows[0])],\n",
    "            label=f'Window {windows[0]} bp')\n",
    "\n",
    "ins_ax.legend(bbox_to_anchor=(0., -1), loc='lower left', ncol=4);\n",
    "\n",
    "format_ticks(ins_ax, y=False, rotate=False)\n",
    "ax.set_xlim(region[1], region[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bec5d7-0751-4766-a6f6-061259483b14",
   "metadata": {},
   "source": [
    "And now let's add the other window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28b600-c7e6-4d15-b79f-e4b152636817",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in windows[1:]:\n",
    "    ins_ax.plot(insul_region[['start', 'end']].mean(axis=1), insul_region[f'log2_insulation_score_{res}'], label=f'Window {res} bp')\n",
    "ins_ax.legend(bbox_to_anchor=(0., -1), loc='lower left', ncol=4);\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38afe61-3301-40e7-be99-47d2cc76141c",
   "metadata": {},
   "source": [
    "This really highlights how much the result is dependent on window size: smaller windows are sensitive to local structure, whereas large windows capture regions that insulate at larger scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb265e-4182-4cfa-a695-6ce57586ce8d",
   "metadata": {},
   "source": [
    "#### Boundary calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87d7bb-eb3b-454b-bf59-3b45cd498428",
   "metadata": {},
   "source": [
    "The insulation table also has annotations for valleys of the insulation score, which correspond to highly insulating regions, such as TAD boundaries. All potential boundaries have an assigned `boundary_strength_` column. Additionally, this strength is thresholded to find regions that insulate particularly strongly, and this is recorded in the `is_boundary_` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75c4b9-df1d-45f9-9fd2-77a4a799723f",
   "metadata": {},
   "source": [
    "Let's repeat the previous plot and show where we found the boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2f470-9bba-44af-82c1-fbce3e5fb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "im = pcolormesh_45deg(ax, data, start=region[1], resolution=resolution, norm=norm, cmap='fall')\n",
    "ax.set_aspect(0.5)\n",
    "ax.set_ylim(0, 10*windows[0])\n",
    "format_ticks(ax, rotate=False)\n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.1, aspect=6)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "insul_region = bioframe.select(insulation_table, region)\n",
    "\n",
    "ins_ax = divider.append_axes(\"bottom\", size=\"50%\", pad=0., sharex=ax)\n",
    "\n",
    "ins_ax.plot(insul_region[['start', 'end']].mean(axis=1),\n",
    "            insul_region[f'log2_insulation_score_{windows[0]}'], label=f'Window {windows[0]} bp')\n",
    "\n",
    "boundaries = insul_region[~np.isnan(insul_region[f'boundary_strength_{windows[0]}'])]\n",
    "weak_boundaries = boundaries[~boundaries[f'is_boundary_{windows[0]}']]\n",
    "strong_boundaries = boundaries[boundaries[f'is_boundary_{windows[0]}']]\n",
    "ins_ax.scatter(weak_boundaries[['start', 'end']].mean(axis=1), \n",
    "            weak_boundaries[f'log2_insulation_score_{windows[0]}'], label='Weak boundaries')\n",
    "ins_ax.scatter(strong_boundaries[['start', 'end']].mean(axis=1), \n",
    "            strong_boundaries[f'log2_insulation_score_{windows[0]}'], label='Strong boundaries')\n",
    "\n",
    "ins_ax.legend(bbox_to_anchor=(0., -1), loc='lower left', ncol=4);\n",
    "\n",
    "format_ticks(ins_ax, y=False, rotate=False)\n",
    "ax.set_xlim(region[1], region[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e662b",
   "metadata": {},
   "source": [
    "### Pileups\n",
    "    \n",
    "[go top](#Workshop-outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ccdb7-9cbc-4278-8177-424863ca2e24",
   "metadata": {},
   "source": [
    "Averaging Hi-C/Micro-C maps allows the quantification of general patterns observed in the maps. Averaging comes in various forms: contact-vs-distance plots, saddle plots, and pileup plots. **Pileup plots** are the averaged local Hi-C map over the 2D windows (i.e. **snippets**). These are also referred to as \"average Hi-C maps\". Pileups can be useful for determining the relationship between features (e.g. CTCF and TAD boundaries). Pileups can also be beneficial for reliably observing features in low-coverage Hi-C or single-cell HiC maps.\n",
    "\n",
    "For pileups, we retrieve local windows that are centered at the **anchors**. We call this procedure **snipping**. Anchors can be ChIP-Seq binding sites, anchors of dots, or any other genomic features. Pileups come in two varieties: \n",
    "\n",
    "- **On-diagonal pileup**. Each window is centered at the pixel located at the anchor position, at the main diagonal. Both coordinates of the window center are equivalent to the bin of the anchor. \n",
    "- **Off-diagonal pileup**. Each window is centered at the pixel with one anchor as a left coordinate and another anchor as a right coordinate. \n",
    "\n",
    "Typically, the sizes of windows are equivalent. After the selection of windows, we average them elementwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c14c75-f30f-48e1-b39b-173c046db316",
   "metadata": {},
   "source": [
    "Content:\n",
    "\n",
    "1. Download data\n",
    "2. Load data\n",
    "    - Load genomic regions\n",
    "    - Load features for anchors\n",
    "3. On-diagonal pipeup of CTCF\n",
    "    - On-diagonal pileup of ICed Hi-C interactions\n",
    "    - On-diagonal pileup of observed over expected interactions\n",
    "    - Inspect the snips\n",
    "4. Off-diagonal pileup of CTCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32284ba3-a2ae-4e52-be61-7d6225b09d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading test data for pileups\n",
    "# cache = True will doanload the data only if it was not previously downloaded\n",
    "data_dir = './data/'\n",
    "cool_file = cooltools.download_data(\"HFF_MicroC\", cache=True, data_dir=data_dir)\n",
    "ctcf_peaks_file = cooltools.download_data(\"HFF_CTCF_binding\", cache=True, data_dir=data_dir)\n",
    "ctcf_fc_file = cooltools.download_data(\"HFF_CTCF_fc\", cache=True, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf269e28-d587-49b2-b93e-6126037ec843",
   "metadata": {},
   "source": [
    "#### Load genomic regions\n",
    "\n",
    "The pileup function needs **genomic regions**. Why?\n",
    "\n",
    "- First, pileup uses regions for parallelization of snipping. Different genomic regions are loaded simultaneously by different processes, and the snipping can be done in parallel. \n",
    "- Second, the observed over expected pileup requires calculating expected interactions before snipping (P(s), in other words). Typically, P(s) is calculated separately for each chromosome arm as inter-arms interactions might be affected by strong insulation of centromeres or Rabl configuration. \n",
    "\n",
    "For species that do not have information on chromosome arms, or have *telocentric chromosomes* (e.g., mouse), you may want to use full chromosomes instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c273faf-85fe-43ae-a7d9-6022996f1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open cool file with Micro-C data:\n",
    "clr = cooler.Cooler(data_dir+'/test.mcool::/resolutions/10000')\n",
    "# Set up selected data resolution:\n",
    "resolution = clr.binsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed16df2-c85a-4c7a-854f-acfa525fbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bioframe to fetch the genomic features from the UCSC.\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes('hg38')\n",
    "hg38_cens = bioframe.fetch_centromeres('hg38')\n",
    "hg38_arms = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "\n",
    "# Select only chromosomes that are present in the cooler. \n",
    "# This step is typically not required! we call it only because the test data are reduced. \n",
    "hg38_arms = hg38_arms.set_index(\"chrom\").loc[clr.chromnames].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dec60-7036-470e-914c-400294b9c0e4",
   "metadata": {},
   "source": [
    "#### Load features for anchors\n",
    "\n",
    "Construction of the pileup requires  genomic **features** that will be used for centering of the **snippets**. In this example, we will use *positions of motifs in CTCF peaks* as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec58b5-f862-4a13-8c8d-0a73ab7f1190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read CTCF peaks data and select only chromosomes present in cooler:\n",
    "ctcf = bioframe.read_table(ctcf_peaks_file, schema='bed').query(f'chrom in {clr.chromnames}')\n",
    "ctcf['mid'] = (ctcf.end+ctcf.start)//2\n",
    "ctcf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aba9c6-0291-4779-98a2-c75224815e42",
   "metadata": {},
   "source": [
    "#### Feature inspection and filtering\n",
    "\n",
    "Since we have both the list of strongest motifs of CTCF located in CTCF ChIP-Seq and the fold change over input for the genome, we have two characteristics of each feature: \n",
    "\n",
    "- score of the motif\n",
    "- CTCF ChIP-Seq fold-change over input\n",
    "\n",
    "Let's take a look at joint distribution of these scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3304539-8fc4-4dc9-98fa-4b03cd18a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bbi\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335628ab-42b1-4038-b170-26afef777554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CTCF ChIP-Seq fold-change over input for genomic regions centered at the positions of the motifs\n",
    "\n",
    "flank = 250 # Length of flank to one side from the boundary, in basepairs\n",
    "ctcf_chip_signal = bbi.stackup(\n",
    "    ctcf_fc_file, \n",
    "    ctcf.chrom, \n",
    "    ctcf.mid-flank, \n",
    "    ctcf.mid+flank, \n",
    "    bins=1)\n",
    "\n",
    "ctcf['FC_score'] = ctcf_chip_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768eee2-3ffd-4bda-ad10-c1b329c61b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcf['quartile_score']    = pd.qcut(ctcf['score'], 4, labels=False) + 1\n",
    "ctcf['quartile_FC_score'] = pd.qcut(ctcf['FC_score'], 4, labels=False) + 1\n",
    "ctcf['peaks_importance'] = ctcf.apply(\n",
    "    lambda x: 'Top by both scores' if x.quartile_score==4 and x.quartile_FC_score==4 else\n",
    "                'Top by Motif score' if x.quartile_score==4 else\n",
    "                'Top by FC score' if x.quartile_FC_score==4 else 'Ordinary peaks', axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a22e9-744c-4f8d-beb8-0412af194905",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ctcf['score']\n",
    "y = np.log(ctcf['FC_score'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=x, y=y, hue=ctcf['peaks_importance'],\n",
    "    s=2,\n",
    "    alpha=0.5,\n",
    "    label='All peaks', \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "slope, intercept, r, p, se = linregress(x, y)\n",
    "\n",
    "ax.plot([-6, 19], [intercept-6*slope, intercept+19*slope], \n",
    "        alpha=0.5,\n",
    "        color='black',\n",
    "        label=f\"Regression line, R value: {r:.2f}\")\n",
    "\n",
    "ax.set(\n",
    "    xlabel='Motif score',\n",
    "    ylabel='ChIP-Seq fold-change over input')\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.01,1), loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b461738-5c44-4bdb-b111-c9076c5d04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the CTCF sites that are in top quartile by both the ChIP-Seq data and motif score\n",
    "\n",
    "sites = ctcf[ctcf['peaks_importance']=='Top by both scores']\\\n",
    "    .sort_values('FC_score', ascending=False)\\\n",
    "    .reset_index(drop=True)\n",
    "sites.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dac03d-6e98-4f3e-8568-278c396e6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some CTCF sites might be located too close in the genome and interfere with analysis. \n",
    "# We will collapse the sites falling into the same size genomic bins as the resolution of our micro-C data:\n",
    "sites = bioframe.cluster(sites, min_dist=resolution)\\\n",
    "    .drop_duplicates('cluster')\\\n",
    "    .reset_index(drop=True)\n",
    "sites.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba4326-e45c-4096-a0c6-17ca09f03aa9",
   "metadata": {},
   "source": [
    "#### On-diagonal pileup\n",
    "\n",
    "On-diagonal pileup is the simplest, you need the positions of **features** (middlepoints of CTCF motifs) and the size of flanks aroung each motif. cooltools will create a snippet of Hi-C map for each feature. Then you can combine them into a single 2D pileup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81039cd1-4909-4db4-a49e-96d150e5cdab",
   "metadata": {},
   "source": [
    "#### On-diagonal pileup of ICed Hi-C interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6609dfe-8894-41c2-bd12-0ee243e29e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = cooltools.pileup(clr, sites, view_df=hg38_arms, flank=300_000)\n",
    "# Mirror reflect snippets when the feature is on the opposite strand\n",
    "mask = np.array(sites.strand == '-', dtype=bool)\n",
    "stack[:, :, mask] = stack[::-1, ::-1, mask]\n",
    "\n",
    "# Aggregate. Note that some pixels might be converted to NaNs after IC, thus we aggregate by nanmean: \n",
    "mtx = np.nanmean(stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99063576-e0bc-4715-ae94-1c558a021778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load colormap with large number of distinguishable intermediary tones,\n",
    "# The \"fall\" colormap in cooltools is exactly for this purpose.\n",
    "# After this step, you can use \"fall\" as cmap parameter in matplotlib:\n",
    "import cooltools.lib.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ff672-6070-46f4-92d9-122f1516485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    np.log10(mtx),\n",
    "    vmin = -3,\n",
    "    vmax = -1,\n",
    "    cmap='fall',\n",
    "    interpolation='none')\n",
    "\n",
    "plt.colorbar(label = 'log10 mean ICed Hi-C')\n",
    "ticks_pixels = np.linspace(0, flank*2//resolution,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*resolution//1000).astype(int)\n",
    "plt.xticks(ticks_pixels, ticks_kbp)\n",
    "plt.yticks(ticks_pixels, ticks_kbp)\n",
    "plt.xlabel('relative position, kbp')\n",
    "plt.ylabel('relative position, kbp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93623c67-d490-4403-add9-6239d6300f86",
   "metadata": {},
   "source": [
    "#### On-diagonal pileup of observed over expected interactions\n",
    "\n",
    "Sometimes you don't want to include the **distance decay** P(s) in your pileups. For example, when you make comparison of pileups between experiments and they have different P(s). Even if these differences are slight, they might affect the pileup of raw ICed Hi-C interactions. \n",
    "\n",
    "In this case, the observed over expected pileup is your choice. Prior to running the pileup function, you need to calculate expected interactions for chromosome arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea03fe-6379-4ced-92d5-8d06e7af81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = cooltools.expected_cis(clr, view_df=hg38_arms, nproc=2, chunksize=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38becd-bc16-47dd-9e57-598705f35311",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a8dbd-b607-4909-b6ae-55ed91dd35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stack of snips:\n",
    "stack = cooltools.pileup(clr, sites, view_df=hg38_arms, expected_df=expected, flank=300_000) \n",
    "\n",
    "# Mirror reflect snippets when the feature is on the opposite strand\n",
    "mask = np.array(sites.strand == '-', dtype=bool)\n",
    "stack[:, :, mask] = stack[::-1, ::-1, mask]\n",
    "    \n",
    "mtx = np.nanmean(stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48357ff2-cf05-4b1a-90e3-54005ac01e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    np.log2(mtx),\n",
    "    vmax = 1.0,\n",
    "    vmin = -1.0,\n",
    "    cmap='coolwarm',\n",
    "    interpolation='none')\n",
    "\n",
    "plt.colorbar(label = 'log2 mean obs/exp')\n",
    "ticks_pixels = np.linspace(0, flank*2//resolution,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*resolution//1000).astype(int)\n",
    "plt.xticks(ticks_pixels, ticks_kbp)\n",
    "plt.yticks(ticks_pixels, ticks_kbp)\n",
    "plt.xlabel('relative position, kbp')\n",
    "plt.ylabel('relative position, kbp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48d81b-1bd2-4d2e-b60a-aee54211e30d",
   "metadata": {},
   "source": [
    "#### Inspect the snips\n",
    "\n",
    "Aggregation is a convenient though dangerous step. It averages your data so that you cannot distinguish whether the signal is indeed average, or there is a single dataset that introduces a bias to your analysis. To make sure there are no outliers, you may want to use inspection of individual snippets.\n",
    "\n",
    "The cell below shows one way to interactively investigate snippets contributing to a pileup. Note that this is not interactive on readthedocs, but can be run if the notebook is obtained from [open2c_examples](https://github.com/open2c/open2c_examples). This widget sorts the dataframe with CTCF motifs by the strength of binding. This allows us to inspect the Micro-C maps at the positions of the strongest and weakest CTCF sites. Run the cell below and try to compare snippets with the lowest score to the snippets with the largest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2128a-586d-4058-8415-2b6e32627499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "n_examples = len(sites)\n",
    "\n",
    "@interact(i=(0, n_examples-1))\n",
    "def f(i):\n",
    "    fig, ax = plt.subplots(figsize=[5,5])\n",
    "    img = ax.matshow(\n",
    "        np.log2(stack[:, :, i]),  \n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        extent=[-flank//1000, flank//1000, -flank//1000, flank//1000],\n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    ax.xaxis.tick_bottom()\n",
    "    if i > 0:\n",
    "        ax.yaxis.set_visible(False)\n",
    "    plt.title(f'{i+1}-th snippet from top \\n FC score: {sites.loc[i, \"FC_score\"]:.2f}\\n and motif score: {sites.loc[i, \"score\"]:.2f}')\n",
    "    plt.axvline(0, c='g', ls=':')\n",
    "    plt.axhline(0, c='g', ls=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd43c5-9e9c-41ea-9193-d3c017c74eec",
   "metadata": {},
   "source": [
    "#### Compare top strongest peaks with others\n",
    "\n",
    "Compare the top peaks with both motif score and FC score to the rest of the peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0e534-20a6-4c0a-a518-0d3640ceb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stack of snips:\n",
    "stack = cooltools.pileup(clr, ctcf, view_df=hg38_arms, expected_df=expected, flank=300_000\n",
    "            ) \n",
    "\n",
    "# Mirror reflect snippets where the feature is on the opposite strand\n",
    "mask = np.array(ctcf.strand == '-', dtype=bool)\n",
    "stack[:, :, mask] = stack[::-1, ::-1, mask]\n",
    "    \n",
    "mtx = np.nanmean(stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4e599-b745-4cb0-bc62-187a76bd2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add some strength of insulation for the pileup? \n",
    "\n",
    "groups = ['Top by both scores', 'Ordinary peaks']\n",
    "n_groups = len(groups)\n",
    "\n",
    "ticks_pixels = np.linspace(0, flank*2//resolution,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*resolution//1000).astype(int)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_groups, sharex=True, sharey=True, figsize=(4*n_groups, 4))\n",
    "for i in range(n_groups):\n",
    "    mtx = np.nanmean( stack[:, :, ctcf['peaks_importance']==groups[i]], axis=2)\n",
    "    ax = axs[i]\n",
    "    ax.imshow(\n",
    "        np.log2(mtx),\n",
    "        vmax = 1.0,\n",
    "        vmin = -1.0,\n",
    "        cmap='coolwarm',\n",
    "        interpolation='none')\n",
    "    \n",
    "    ax.set(title=f'{groups[i]} group', \n",
    "           xticks=ticks_pixels, \n",
    "           xticklabels=ticks_kbp, \n",
    "           xlabel='relative position, kbp')\n",
    "\n",
    "axs[0].set(yticks=ticks_pixels, \n",
    "       yticklabels=ticks_kbp, \n",
    "       ylabel='relative position, kbp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201df5af-2199-4e45-a687-9e1a715604e5",
   "metadata": {},
   "source": [
    "#### Off-diagonal pileup\n",
    "\n",
    "**Off-diagonal pileups** are the averaged Hi-C maps around double anchors. In this case, the anchors are CTCF sites in the genome. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a38770-485f-45ca-9806-710840088de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_sites = bioframe.pair_by_distance(sites, min_sep=200000, max_sep=1000000, suffixes=('1', '2'))\n",
    "paired_sites.loc[:, 'mid1'] = (paired_sites['start1'] + paired_sites['end1'])//2\n",
    "paired_sites.loc[:, 'mid2'] = (paired_sites['start2'] + paired_sites['end2'])//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acf2e9-7076-4f0c-9d2a-9a0aaedf2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(paired_sites))\n",
    "paired_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f75c2-7a37-40d1-84a5-e2c515009407",
   "metadata": {},
   "source": [
    "For pileup, we will use the expected calculated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca50591-89f0-4648-a9a0-8c4688407f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the stack of snips:\n",
    "stack = cooltools.pileup(clr, paired_sites, view_df=hg38_arms, expected_df=expected, flank=100_000)\n",
    "    \n",
    "mtx = np.nanmean(stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155a3b7-55b1-407b-bf95-1d61dcd5eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    np.log2(mtx),\n",
    "    vmax = 1,\n",
    "    vmin = -1,\n",
    "    cmap='coolwarm')\n",
    "\n",
    "plt.colorbar(label = 'log2 mean obs/exp')\n",
    "ticks_pixels = np.linspace(0, flank*2//resolution,5)\n",
    "ticks_kbp = ((ticks_pixels-ticks_pixels[-1]/2)*resolution//1000).astype(int)\n",
    "plt.xticks(ticks_pixels, ticks_kbp)\n",
    "plt.yticks(ticks_pixels, ticks_kbp)\n",
    "plt.xlabel('relative position, kbp')\n",
    "plt.ylabel('relative position, kbp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7f4ca",
   "metadata": {},
   "source": [
    "### Compartments\n",
    "    \n",
    "[go top](#Workshop-outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c9ccf-aac6-484e-b885-26eea183abeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculating per-chromosome compartmentalization\n",
    "\n",
    "We first load the Hi-C data at 100 kbp resolution. \n",
    "\n",
    "Note that the current implementation of eigendecomposition in cooltools assumes that individual regions can be held in memory-- for hg38 at 100kb this is either a 2422x2422 matrix for chr2, or a 3255x3255 matrix for the full cooler here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef651481-bc4f-45e8-b86b-b7a44aa57670",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = cooler.Cooler('./data/test.mcool::resolutions/100000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462312f-320e-42b7-9bf3-afefb8a50120",
   "metadata": {},
   "source": [
    "Since the orientation of eigenvectors is determined up to a sign, the convention for Hi-C data anaylsis is to orient eigenvectors to be positively correlated with a binned profile of GC content as a 'phasing track'. \n",
    "\n",
    "In humans and mice, GC content is useful for phasing because it typically has a strong correlation at the 100kb-1Mb bin level with the eigenvector. In other organisms, other phasing tracks have been used to orient\n",
    "eigenvectors from Hi-C data. \n",
    "\n",
    "For other data analyses, different conventions are used to consistently orient eigenvectors. For example, spectral clustering as implemented in [scikit-learn](\n",
    "https://github.com/scikit-learn/scikit-learn/blob/03245ee3afe5ee9e2ff626e2290f02748d95e497/sklearn/utils/extmath.py#L1041) orients vectors such that the absolute maximum element of each vector is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687a8e9-9f98-4be2-b394-6bc607adf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86080e9b-f887-4201-9f92-3989ed3d39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fasta sequence is required for calculating binned profile of GC conent\n",
    "if not os.path.isfile('./hg38.fa'):\n",
    "    ## note downloading a ~1Gb file can take a minute\n",
    "    subprocess.call('wget https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.fa.gz', shell=True,\n",
    "                    stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    subprocess.call('gunzip hg38.fa.gz', shell=True,\n",
    "                    stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494178c0-c479-4fbf-80ef-d8aa76ac455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioframe\n",
    "bins = clr.bins()[:]\n",
    "hg38_genome = bioframe.load_fasta('./hg38.fa');\n",
    "## note the next command may require installing pysam\n",
    "gc_cov = bioframe.frac_gc(bins[['chrom', 'start', 'end']], hg38_genome)\n",
    "gc_cov.to_csv('hg38_gc_cov_100kb.tsv',index=False,sep='\\t')\n",
    "display(gc_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab666409-96ca-458b-a984-d5ab21529c6f",
   "metadata": {},
   "source": [
    "Cooltools also allows a view to be passed for eigendecomposition to limit to a certain set of regions. The following code creates the simplest view, of the two chromosomes in this cooler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2580405-2f1a-4433-a533-35fc2be91081",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df = pd.DataFrame({'chrom': clr.chromnames,\n",
    "                        'start': 0,\n",
    "                        'end': clr.chromsizes.values,\n",
    "                        'name': clr.chromnames}\n",
    "                      )\n",
    "display(view_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90e12d-39cc-4a5a-bbef-0940870f8deb",
   "metadata": {},
   "source": [
    "To capture the pattern of compartmentalization within-chromosomes, in cis, cooltools `eigs_cis` first removes\n",
    "the dependence of contact frequency by distance, and then performs eigenedecompostion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444c23d-58d6-4084-a4f1-411f76785e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain first 3 eigenvectors\n",
    "cis_eigs = cooltools.eigs_cis( \n",
    "                        clr, \n",
    "                        gc_cov, \n",
    "                        view_df=view_df, \n",
    "                        n_eigs=3,\n",
    "                        )\n",
    "\n",
    "# cis_eigs[0] returns eigenvalues, here we focus on eigenvectors\n",
    "eigenvector_track = cis_eigs[1][['chrom','start','end','E1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fe312-9f1c-499f-9fed-ef39f9c913fe",
   "metadata": {},
   "source": [
    "Plotting the first eigenvector next to the Hi-C map allows us to see how this captures the plaid pattern. \n",
    "\n",
    "To better visualize this relationship, we overlay the map with a binary segmentation of the eigenvector. Eigenvectors can be segmented by a variety of methods. The simplest segmentation, shown here, is to simply binarize eigenvectors, and term everything above zero the \"A-compartment\" and everything below 0 the \"B-compartment\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125d232-fa49-4ad8-9484-3ac4804cf816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "f, ax = plt.subplots(\n",
    "    figsize=(15, 10),\n",
    ")\n",
    "\n",
    "norm = LogNorm(vmax=0.1)\n",
    "\n",
    "im = ax.matshow(\n",
    "    clr.matrix()[:], \n",
    "    norm=norm,  \n",
    "    cmap='fall'\n",
    "); \n",
    "plt.axis([0,500,500,0])\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.01)\n",
    "plt.colorbar(im, cax=cax, label='corrected frequencies');\n",
    "ax.set_ylabel('chr2:0-50Mb')\n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "ax1 = divider.append_axes(\"top\", size=\"20%\", pad=0.25, sharex=ax)\n",
    "weights = clr.bins()[:]['weight'].values\n",
    "ax1.plot([0,500], [0,0], 'k',lw=0.25)\n",
    "ax1.plot( eigenvector_track['E1'].values, label='E1')\n",
    "\n",
    "ax1.set_ylabel('E1')\n",
    "ax1.set_xticks([]);\n",
    "\n",
    "\n",
    "for i in np.where(np.diff( (cis_eigs[1]['E1']>0).astype(int)))[0]:\n",
    "    ax.plot([0, 500],[i,i],'k',lw=0.5)\n",
    "    ax.plot([i,i],[0, 500],'k',lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251c82-a319-4080-af10-65acec124bbc",
   "metadata": {},
   "source": [
    "### Saddle plots\n",
    "\n",
    "[go top](#Workshop-outline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48750062-2701-41c9-b917-f40a0ab098f9",
   "metadata": {},
   "source": [
    "A common way to visualize preferences captured by the eigenvector is by using saddleplots.\n",
    "\n",
    "To generate a saddleplot, we first use the eigenvector to stratify genomic regions into groups with similar values of the eigenvector. These groups are then averaged over to create the saddleplot.\n",
    "This process is called \"digitizing\".\n",
    "\n",
    "Cooltools will operate with `digitized` bedgraph-like track with four columns. The fourth, or value, column is a categorical, as shown above for the first three bins. Categories have the following encoding:\n",
    "\n",
    "    - `1..n` <-> values assigned to bins defined by vrange or qrange\n",
    "    - `0` <-> left outlier values\n",
    "    - `n+1` <-> right outlier values\n",
    "    - `-1` <-> missing data (NaNs)\n",
    "    \n",
    "Track values can either be digitized by numeric values, by passing `vrange`, or by quantiles, by passing `qrange`, as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ca734-20d0-42a2-934d-8f98a591a2fc",
   "metadata": {},
   "source": [
    "To create saddles in cis with `saddle`, cooltools requires: a cooler, a table with expected as function of distance, and parameters for digitizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b653280-5757-46e2-886d-bf987492b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd = cooltools.expected_cis(\n",
    "        clr=clr,\n",
    "        view_df=view_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffc085-59fc-4dcd-9622-4cfa7fc5a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_LO = 0.025 # ignore 2.5% of genomic bins with the lowest E1 values\n",
    "Q_HI = 0.975 # ignore 2.5% of genomic bins with the highest E1 values\n",
    "N_GROUPS = 38 # divide remaining 95% of the genome into 38 equisized groups, 2.5% each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85488498-5290-4360-b7d1-4bd9ae05e66e",
   "metadata": {},
   "source": [
    "`saddle` then returns two matrices: one with the sum for each pair of categories, `interaction_sum`, and the other with the number of bins for each pair of categories, `interaction_count`. Typically, `interaction_sum`/`interaction_count` is visualized. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd1776-abc8-4695-8564-14b340407c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_sum, interaction_count =  cooltools.saddle(\n",
    "        clr,\n",
    "        cvd,\n",
    "        eigenvector_track,\n",
    "        'cis',\n",
    "        n_bins=N_GROUPS,\n",
    "        qrange=(Q_LO,Q_HI),\n",
    "        view_df=view_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246de35-c362-44ff-8177-b5310b2df710",
   "metadata": {},
   "source": [
    "There are multiple ways to plot saddle data, one useful way is shown below. \n",
    "\n",
    "This visualization includes histograms of the number of bins contributing to each row/column of the saddleplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eeeb8f-68ab-4daa-a240-f542b76264eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from cytoolz import merge\n",
    "\n",
    "def saddleplot(\n",
    "    track,\n",
    "    saddledata,\n",
    "    n_bins,\n",
    "    vrange=None,\n",
    "    qrange=(0.0, 1.0),\n",
    "    cmap=\"coolwarm\",\n",
    "    scale=\"log\",\n",
    "    vmin=0.5,\n",
    "    vmax=2,\n",
    "    color=None,\n",
    "    title=None,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    clabel=None,\n",
    "    fig=None,\n",
    "    fig_kws=None,\n",
    "    heatmap_kws=None,\n",
    "    margin_kws=None,\n",
    "    cbar_kws=None,\n",
    "    subplot_spec=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a saddle plot.\n",
    "    Parameters\n",
    "    ----------\n",
    "    track : pd.DataFrame\n",
    "        See cooltools.digitize() for details.\n",
    "    saddledata : 2D array-like\n",
    "        Saddle matrix produced by `make_saddle`. It will include 2 flanking\n",
    "        rows/columns for outlier signal values, thus the shape should be\n",
    "        `(n+2, n+2)`.\n",
    "    cmap : str or matplotlib colormap\n",
    "        Colormap to use for plotting the saddle heatmap\n",
    "    scale : str\n",
    "        Color scaling to use for plotting the saddle heatmap: log or linear\n",
    "    vmin, vmax : float\n",
    "        Value limits for coloring the saddle heatmap\n",
    "    color : matplotlib color value\n",
    "        Face color for margin bar plots\n",
    "    fig : matplotlib Figure, optional\n",
    "        Specified figure to plot on. A new figure is created if none is\n",
    "        provided.\n",
    "    fig_kws : dict, optional\n",
    "        Passed on to `plt.Figure()`\n",
    "    heatmap_kws : dict, optional\n",
    "        Passed on to `ax.imshow()`\n",
    "    margin_kws : dict, optional\n",
    "        Passed on to `ax.bar()` and `ax.barh()`\n",
    "    cbar_kws : dict, optional\n",
    "        Passed on to `plt.colorbar()`\n",
    "    subplot_spec : GridSpec object\n",
    "        Specify a subregion of a figure to using a GridSpec.\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of axes objects.\n",
    "    \"\"\"\n",
    "\n",
    "#     warnings.warn(\n",
    "#         \"Generating a saddleplot will be deprecated in future versions, \"\n",
    "#         + \"please see https://github.com/open2c_examples for examples on how to plot saddles.\",\n",
    "#         DeprecationWarning,\n",
    "#     )\n",
    "\n",
    "    from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "    from matplotlib.colors import Normalize, LogNorm\n",
    "    from matplotlib import ticker\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    class MinOneMaxFormatter(ticker.LogFormatter):\n",
    "        def set_locs(self, locs=None):\n",
    "            self._sublabels = set([vmin % 10 * 10, vmax % 10, 1])\n",
    "\n",
    "        def __call__(self, x, pos=None):\n",
    "            if x not in [vmin, 1, vmax]:\n",
    "                return \"\"\n",
    "            else:\n",
    "                return \"{x:g}\".format(x=x)\n",
    "\n",
    "    track_value_col = track.columns[3]\n",
    "    track_values = track[track_value_col].values\n",
    "\n",
    "    digitized_track, binedges = cooltools.digitize(\n",
    "        track, n_bins, vrange=vrange, qrange=qrange\n",
    "    )\n",
    "    x = digitized_track[digitized_track.columns[3]].values.astype(int).copy()\n",
    "    x = x[(x > -1) & (x < len(binedges) + 1)]\n",
    "    \n",
    "    # Old version\n",
    "    # hist = np.bincount(x, minlength=len(binedges) + 1)\n",
    "\n",
    "    groupmean = track[track.columns[3]].groupby(digitized_track[digitized_track.columns[3]]).mean()\n",
    "    \n",
    "    if qrange is not None:\n",
    "        lo, hi = qrange\n",
    "        binedges = np.linspace(lo, hi, n_bins + 1)\n",
    "    \n",
    "    # Barplot of mean values and saddledata are flanked by outlier bins\n",
    "    n = saddledata.shape[0]\n",
    "    X, Y = np.meshgrid(binedges, binedges)\n",
    "    C = saddledata\n",
    "    if (n - n_bins) == 2:\n",
    "        C = C[1:-1, 1:-1]\n",
    "        groupmean = groupmean[1:-1]\n",
    "\n",
    "    # Layout\n",
    "    if subplot_spec is not None:\n",
    "        GridSpec = partial(GridSpecFromSubplotSpec, subplot_spec=subplot_spec)\n",
    "    grid = {}\n",
    "    gs = GridSpec(\n",
    "        nrows=3,\n",
    "        ncols=3,\n",
    "        width_ratios=[0.2, 1, 0.1],\n",
    "        height_ratios=[0.2, 1, 0.1],\n",
    "        wspace=0.05,\n",
    "        hspace=0.05,\n",
    "    )\n",
    "\n",
    "    # Figure\n",
    "    if fig is None:\n",
    "        fig_kws_default = dict(figsize=(5, 5))\n",
    "        fig_kws = merge(fig_kws_default, fig_kws if fig_kws is not None else {})\n",
    "        fig = plt.figure(**fig_kws)\n",
    "\n",
    "    # Heatmap\n",
    "    if scale == \"log\":\n",
    "        norm = LogNorm(vmin=vmin, vmax=vmax)\n",
    "    elif scale == \"linear\":\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        raise ValueError(\"Only linear and log color scaling is supported\")\n",
    "\n",
    "    grid[\"ax_heatmap\"] = ax = plt.subplot(gs[4])\n",
    "    heatmap_kws_default = dict(cmap=\"coolwarm\", rasterized=True)\n",
    "    heatmap_kws = merge(\n",
    "        heatmap_kws_default, heatmap_kws if heatmap_kws is not None else {}\n",
    "    )\n",
    "    img = ax.pcolormesh(X, Y, C, norm=norm, **heatmap_kws)\n",
    "    plt.gca().yaxis.set_visible(False)\n",
    "\n",
    "    # Margins\n",
    "    margin_kws_default = dict(edgecolor=\"k\", facecolor=color, linewidth=1)\n",
    "    margin_kws = merge(margin_kws_default, margin_kws if margin_kws is not None else {})\n",
    "    # left margin hist\n",
    "    grid[\"ax_margin_y\"] = plt.subplot(gs[3], sharey=grid[\"ax_heatmap\"])\n",
    "    \n",
    "    plt.barh(\n",
    "        binedges, height=1/len(binedges), width=groupmean, align=\"edge\", **margin_kws\n",
    "    )\n",
    "    \n",
    "    plt.xlim(plt.xlim()[1], plt.xlim()[0])  # fliplr\n",
    "    plt.ylim(hi, lo)\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"bottom\"].set_visible(False)\n",
    "    plt.gca().spines[\"left\"].set_visible(False)\n",
    "    plt.gca().xaxis.set_visible(False)\n",
    "    # top margin hist\n",
    "    grid[\"ax_margin_x\"] = plt.subplot(gs[1], sharex=grid[\"ax_heatmap\"])\n",
    "    \n",
    "    plt.bar(\n",
    "        binedges, width=1/len(binedges), height=groupmean, align=\"edge\", **margin_kws\n",
    "    )\n",
    "    \n",
    "    plt.xlim(lo, hi)\n",
    "    # plt.ylim(plt.ylim())  # correct\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "    plt.gca().spines[\"left\"].set_visible(False)\n",
    "    plt.gca().xaxis.set_visible(False)\n",
    "    plt.gca().yaxis.set_visible(False)\n",
    "\n",
    "#     # Colorbar\n",
    "    grid[\"ax_cbar\"] = plt.subplot(gs[5])\n",
    "    cbar_kws_default = dict(fraction=0.8, label=clabel or \"\")\n",
    "    cbar_kws = merge(cbar_kws_default, cbar_kws if cbar_kws is not None else {})\n",
    "    if scale == \"linear\" and vmin is not None and vmax is not None:\n",
    "        grid[\"ax_cbar\"] = cb = plt.colorbar(img, **cbar_kws)\n",
    "        # cb.set_ticks(np.arange(vmin, vmax + 0.001, 0.5))\n",
    "        # # do linspace between vmin and vmax of 5 segments and trunc to 1 decimal:\n",
    "        decimal = 10\n",
    "        nsegments = 5\n",
    "        cd_ticks = np.trunc(np.linspace(vmin, vmax, nsegments) * decimal) / decimal\n",
    "        cb.set_ticks(cd_ticks)\n",
    "    else:\n",
    "        print('cbar')\n",
    "        \n",
    "        cb = plt.colorbar(img, format=MinOneMaxFormatter(), cax=grid[\"ax_cbar\"], **cbar_kws)\n",
    "        cb.ax.yaxis.set_minor_formatter(MinOneMaxFormatter())\n",
    "\n",
    "    # extra settings\n",
    "    grid[\"ax_heatmap\"].set_xlim(lo, hi)\n",
    "    grid[\"ax_heatmap\"].set_ylim(hi, lo)\n",
    "    grid['ax_heatmap'].grid(False)\n",
    "    if title is not None:\n",
    "        grid[\"ax_margin_x\"].set_title(title)\n",
    "    if xlabel is not None:\n",
    "        grid[\"ax_heatmap\"].set_xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        grid[\"ax_margin_y\"].set_ylabel(ylabel)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6d349-20bf-43cc-82e6-dfdad536b837",
   "metadata": {},
   "source": [
    "The saddle below shows average observed/expected contact frequency between regions grouped according to their digitized eigenvector values with a blue-to-white-to-red colormap. Inactive regions (i.e. low digitized values) are on the top and left, and active regions (i.e. high digitized values) are on the bottom and right. \n",
    "\n",
    "The saddleplot shows that inactive regions are enriched for contact frequency with other inactive regions (red area in the upper left), and active regions are enriched for contact frequency with other active regions (red area in the lower right). In contrast, active regions are depleted for contact frequency with inactive regions (blue area in top right and bottom left). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1dfd4-c9d5-4513-90e0-e7126b40097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saddleplot(eigenvector_track, \n",
    "           interaction_sum/interaction_count,\n",
    "           N_GROUPS, \n",
    "           qrange=(Q_LO,Q_HI), \n",
    "           cbar_kws={'label':'average observed/expected contact frequency'}\n",
    "          );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e6edb-71e0-4bb7-8c42-1586988af37b",
   "metadata": {},
   "source": [
    "#### Saddle strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ec4bc-3529-4915-9b06-564094f116ce",
   "metadata": {},
   "source": [
    "Comparing the average obs/expected values between active and inactive chromatin, is one useful measure of the strength of compartmentalization. This can be measured with `saddle_strength()`, which can be thought of as taking the ratio between (AA+BB) / (AB+BA). This corresponds visually to the ratio between the upper left and lower right corners, versus the lower left and upper right corners in the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1e452-3ede-4899-9a22-1e8be07f782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cooltools.api.saddle import saddle_strength\n",
    "# at extent=0, this reduces to ((S/C)[0,0] + (S/C)[-1,-1]) / (2*(S/C)[-1,0])\n",
    "\n",
    "x = np.arange(N_GROUPS + 2)\n",
    "\n",
    "plt.step(x, saddle_strength(interaction_sum, interaction_count), where='pre')\n",
    "\n",
    "plt.xlabel('extent')\n",
    "plt.ylabel('(AA + BB) / (AB + BA)')\n",
    "plt.title('saddle strength profile')\n",
    "plt.axhline(0, c='grey', ls='--', lw=1) # Q: is there a reason this is 0 not 1?\n",
    "plt.xlim(0, len(x)//2); # Q: is this less intuitive than showing for all x, as it converges to no difference (i.e. 1)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485b3a8-5bfe-404f-844f-a87f75a7359a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
